---
layout: post
title: "My Favorite Bits of OSDI/ATC'23"




related_posts:
  - "/2025/06/02/hotos"
  - "/2020/06/08/virtualization"
  - "/2015/03/29/formal"
---
{{ page.title }}
================

<p class="meta">Talking to 3D people is cool again.</p>

This week brought [USENIX ATC'23](https://www.usenix.org/conference/atc23/technical-sessions) and [OSDI'23](https://www.usenix.org/conference/osdi23/technical-sessions) together in Boston. While I've followed OSDI and ATC papers for years, it's the first time I've been to either of them (I've have been to NSDI a couple times). It was a really good time. In this post I'll cover a couple of my favorite papers<sup>[1](#foot1)</sup>, and trends I noticed.

Overall, it was great to meet a bunch of folks in person who I've only interacted with online, and nice to be back to in-person conferences.

**Thoughts and Trends**

1. When we presented the [Firecracker paper](https://www.usenix.org/conference/nsdi20/presentation/agache) at NSDI'20, several people said to me that they were worried about the fact we had chosen Rust, because it raised the risk that Firecracker wouldn't be useful once Rust was no longer in vogue. This year at OSDI, pretty much everybody I talked to was building in Rust. Obvious exceptions are folks doing AI/ML work (Python still seems big there), and folks looking to get into the mainline Linux kernel. I couldn't be more happy to see memory safety start to become the default practice in systems.

2. Loads of folks were talking about emergent system properties like [metastability](https://brooker.co.za/blog/2021/05/24/metastable.html). Unfortunately, not a lot of folks seem to be writing papers about it, or getting grants to work on it. I did talk to a couple folks with upcoming papers, and I really hope the hallway interest turns into more publications. [Metastable failures in distributed systems](https://dl.acm.org/doi/10.1145/3458336.3465286) and [Metastable Failures in the Wild](https://www.usenix.org/conference/osdi22/presentation/huang-lexiang) are some of the most important systems work of the last few years, in my opinion. There's a lot more to do here.

3. I got a rough feeling that more papers were paying more attention to security issues than in years past. Subtle issues like timing side-channels especially. Another trend I like to see. Security and systems have always been linked, so this isn't new, but there does seem to be a reduction in completely security-naive work.

**Some of the Papers I Enjoyed The Most**

* [Take Out the Trache](https://www.usenix.org/conference/osdi23/presentation/cheng) by Audrey Cheng et al<sup>[2](#foot2)</sup>. This paper makes an astute observation about how caches help with latency the most when everything a transaction needs is cached, and so traditional cache eviction strategies don't make the right decisions. They then present new metrics, and a nice design for improving things. Worth reading if you're building any kind of database or distributed cache.
* [VectorVisor](https://www.usenix.org/conference/atc23/presentation/ginzburg) by Samuel Ginzburg et al. What if we compiled normal applications to WASM, then ran them on GPUs? And it actually worked? This is the kind of academic systems work I love the most: bold, innovative, and solving a problem that doesn't really exist yet but definitely could in the future.
* [EPF: Evil Packet Filter](https://www.usenix.org/conference/atc23/presentation/jin) by Di Jin et al. Operating system kernels like Linux use various internal mechanisms that make it harder to go from kernel bug to working exploit. This paper looks at how useful the current BPF implementation can be for thwarting these mechanisms.
* [Triangulating Python Performance Issues with SCALENE](https://www.usenix.org/conference/osdi23/presentation/berger) by Emery Berger et al. A selection of cool approaches for profiling CPU, GPU, and memory in Python programs. Emery finished his talk with a tantalizing demo: generating performance patches automatically by combining LLMs with profiler results.

There are many papers I haven't read yet, but have heard good things about. I want to look at [MELF](https://www.usenix.org/conference/atc23/presentation/tollner), [zpoline](https://www.usenix.org/conference/atc23/presentation/yasukata), [Ens≈ç](https://www.usenix.org/conference/osdi23/presentation/sadok), and [vMVCC](https://www.usenix.org/conference/osdi23/presentation/chang) in more detail.

**Amazon's Papers**

We presented two papers at ATC this year:

* [On-demand container loading in AWS Lambda](https://www.usenix.org/conference/atc23/presentation/brooker) by me, Mike Danilov, Chris Greenwood, and Phil Piwonka. I wrote a post about this paper [back in May](https://brooker.co.za/blog/2023/05/23/snapshot-loading.html). We won a best paper award for this work!
* [Distributed Transactions at Scale in Amazon DynamoDB](https://www.usenix.org/conference/atc23/presentation/idziorek) by a great group of folks from the DynamoDB team, looks at DynamoDB's serializable atomic transaction scheme based on Timestamp Ordering (TO) and 2PC. This paper is a perfect antidote to the widespread idea that transactions can't or don't scale. Combined with the team's [ATC'22 paper](https://www.usenix.org/conference/atc22/presentation/elhemali), this is an excellent deep dive into how a massive scale ([105.2 million TPS for one workload](https://aws.amazon.com/blogs/aws/amazon-prime-day-2022-aws-for-the-win/)) database works under the covers.

**Cloning and Snapshot Safety**

A number of papers in the program implemented VM or process cloning, typically for accelerating serverless workloads. This thread of work, related to our [own work on Lambda Snapstart](https://brooker.co.za/blog/2022/11/29/snapstart.html), is bound to have a lot of influence over how systems are built in the coming decades. But I was disappointed to see most of these papers not paying attention to some of the *uniqueness* risks of cloning. As we describe in [Restoring Uniqueness in MicroVM Snapshots](https://arxiv.org/pdf/2102.12892.pdf), naively cloning VMs leads to situations where UUIDs, cryptographic keys, or IVs can be duplicated between clones. I'd love to see folks working on cloning insist on solving this problem in their solutions.

**Soapbox**

Two things came up that I found extremely disappointing. First, there were a lot of folks who should have been there (especially paper authors) who couldn't get visas to come to the US. It's unacceptable and counterproductive to have a visa policy where folks who are doing cutting-edge research in an economically-critical areas can't trivially travel to the USA. 

Second, a group of folks presented the results of the *CS Conference Climate & Harassment Survey*. I'd recommend reading [Dan Ports' post](https://fediscience.org/@dan@discuss.systems/110697210451922952) for a summary of the results. In short, 40% of the community have experienced harassment at conferences (not necessarily this conference, or a USENIX conference), and 30% of non-male attendees don't feel welcome. This is  unacceptable, and we need to do better<sup>[3](#foot3)</sup>.

**Footnotes**

1. <a name="foot1"></a> These are some of my favorites of the ones I've read, or saw talks for. If you presented a paper and it's not on this list, you can safely assume I haven't had time to check out your excellent work yet.
2. <a name="foot2"></a> Great DB work from the folks at UC Berkley? Hard to believe.
3. <a name="foot3"></a> I unfortunately missed the dedicated session on this topic, and look forward to attending similar sessions at future conferences.